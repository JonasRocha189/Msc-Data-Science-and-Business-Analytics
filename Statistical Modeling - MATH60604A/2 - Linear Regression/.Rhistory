intention <- read.csv("ch2_part2_A_code/intention.csv")
head(intention)
### 1 - Model
mod <- lm(intent~fix+emo+age+sex+stat, data = intention)
summary(mod)
# Creating indicator variables
intention$educ1 <-  as.numeric(intention$educ == 1)
intention$educ2 <-  as.numeric(intetnion$educ == 2)
intention$educ2 <-  as.numeric(intention$educ == 2)
intention$educ3 <-  as.numeric(intention$educ == 3)
head(intention)
# verification
attach(intention)
table(educ, educ1)
table(educ, educ2)
table(educ, educ3)
summary(educ1 +educ2 + educ3)
mod2 <- lm(intent ~ educ1 + educ2, data = intention)
summary(mod2)
mod2.1 <- lm(intent ~ educ1 + educ2, data = intention)
summary(mod2.1)
View(mod2)
mod2.2 <- lm(intent ~ educ1 + educ3, data = intention)
summary(mod2.2)
mod2.3 <- lm(intent ~ educ2 + educ3, data = intention)
summary(mod2.3)
# no need to use all educ varibles
mod2.4 <- lm(intent ~ educ1 + educ2 + educ3, data = intention)
summary(mod2.4)
# as.factor
mod2.5 <- lm(intent ~ as.factor(educ), data = intention)
summary(mod2.5)
# Change the reference level
intention$edu <- relevel(as.factor(intention$edu), ref=2)
# Change the reference level
intention$educ <- relevel(as.factor(intention$edu), ref=2)
# Change the reference level
intention$educ <- relevel(as.factor(intention$educ), ref=2)
mod2.6 <- lm(intent ~ educ, data = intention)
summary(mod2.6)
# all comparisons
install.packages("emmenas")
library(emmeans)
comp <- emmeans(mod2.6, ~educ)
comp
contrast(comp, method="pairwise", adjuste="none")
### 3 - Test global effects
mod <- lm(intent ~ sex + age + as.factor(rev) + as.factor(educ) + stat + fix + emo, data=intention)
summary(mod)
# Sequention SS
anova(mod)
# SSR (here, i.e. SSE(reduced) - SSE(full) where reduced model is an intercept only model )
sum(anova(mod)[1:7,2])
# p
sum(anova(mod)[1:7,1])
# SSE(full)
anova(mod)[8,2]
# n-p-1
anova(mod)[8,1]
# p-value
pf(9.988936,9,110,lower.tail=FALSE)
# model without X1,...,Xp
null<-lm(intent~1,data=intention)
summary(null)
# SST
anova(null)
## global f-test
anova(mod,null)
# Test F:
# effets des variables individuellement
# individual variable effects
library(car)
Anova(mod)
?Anova
# another way to proceed for categorical variables to compare the model with and without education
mod.no.edu<-lm(intent~fix+emo+sex+age+as.factor(rev)+stat,data=intention)
anova(mod,mod.no.edu)
datapred <- intetion[1:10,]
datapred
datapred <- intetion[1:10,]
datapred <- intention[1:10,]
datapred
pred <- predict.lm(mod, newdata=datapred)
cbind(datapred, pred)
resid <- rstudent(mod)
fitted <- mod$fitted.values
res.data <- cbind(intention, fitted, resid)
head(res.data)
res.dat <- cbind(intention, fitted, resid)
head(res.dat)
# Histogram
library(ggplot2)
ggplot(data=res.dat, mapping=aes(x=resid)) +
geom_density() +
geom_histogram(aes(y= ..density..), bins=10, alpha=0.5) +
xlab("residuals")
# qqplot
ggplot(data = res.dat, mapping = aes(sample = resid)) +
stat_qq(distribution = qt, dparams = mod$df.residua) +
stat_qq_line(distribution = qt, dparams = mod$df.residual) +
labs(x = "theoretical quantiles",
y = "empirical quantiles") +
ggtitle("QQ-Plot Studentized Residuals")
# resid vs. fix + smooth
ggplot(data = res.dat,
aes(x = fix, y = resid)) +
geom_point() +
geom_smooth() +
theme(legend.position = "bottom") +
ylab("residuals") +
xlab("fixation")
# resid vs. emo + smooth
ggplot(data = res.dat,
aes(x = emo, y = resid)) +
geom_point() +
geom_smooth() +
theme(legend.position = "bottom") +
ylab("residuals") +
xlab("emotion")
# resid vs. age + smooth
ggplot(data = res.dat,
aes(x = age, y = resid)) +
geom_point() +
geom_smooth() +
theme(legend.position = "bottom") +
ylab("residuals") +
xlab("age")
# resid vs. age + smooth
ggplot(data = res.dat, aes(x = age, y = resid)) +
geom_point() +
geom_smooth() +
theme(legend.position = "bottom") +
ylab("residuals") +
xlab("age")
tapply(res.dat$resid,as.factor(res.dat$sex),function(x) c(mean(x),var(x)) )
# resid vs. sex
ggplot(res.dat, aes(x=as.factor(sex), y=resid)) +
geom_boxplot() +
labs(title="Residuals",x="sex", y = "residuals")
# resid vs. rev
ggplot(res.dat, aes(x=as.factor(rev), y=resid)) +
geom_boxplot() +
labs(title="Residuals",x="rev", y = "residuals")
tapply(res.dat$resid,as.factor(res.dat$rev),function(x) c(mean(x),var(x)) )
# resid vs. educ
ggplot(res.dat, aes(x=as.factor(educ), y=resid)) +
geom_boxplot() +
labs(title="Residuals",x="educ", y = "residuals")
tapply(res.dat$resid,as.factor(res.dat$educ),function(x) c(mean(x),var(x)) )
# resid vs. stat
ggplot(res.dat, aes(x=as.factor(stat), y=resid)) +
geom_boxplot() +
labs(title="Residuals",x="stat", y = "residuals")
tapply(res.dat$resid,as.factor(res.dat$stat),function(x) c(mean(x),var(x)) )
# resid vs. fitted + smooth
ggplot(data = res.dat, aes(x = fitted, y = resid)) +
geom_point() +
geom_smooth() +
theme(legend.position = "bottom") +
ylab("residuals") +
xlab("fitted values")
mod<-lm(intent~sex+age+as.factor(rev)+as.factor(educ)+stat+fix+emo,data=intention)
summary(mod)
null<-lm(intent~1,data=intention)
summary(null)
# by hand
# break-down:
anova(mod) # (sequential SS)
# SSR
SSR<-sum(anova(mod)[1:7,2])
SSR
# SSE
SSE<-anova(mod)[8,2]
SSE
# SST
anova(null)
SST<-anova(null)[,2]
SST
# R2
SSR/SST
# sigma-hat
np1<-anova(mod)[8,1]
sqrt(SSE/np1)
summary(mod)
### 7 - Non-linear effects
reglin2 <- read.csv("ch2_part2_A_code/reglin2.csv")
head(reglin2)
# quadratic term for X
nlmod1<-lm(y~x+I(xˆ2),data=reglin2)
# quadratic term for X
nlmod1<-lm(y ~ x+I(x^2),data=reglin2)
summary(nlmod1)
# plot
ggplot(reglin2, aes(x=x, y=y)) +
geom_point() +
stat_smooth(aes(y = y),method = "lm", formula = y ~ x + I(xˆ2), size = 1)
# plot
ggplot(reglin2, aes(x=x, y=y)) +
geom_point() +
stat_smooth(aes(y = y),method = "lm", formula = y ~ x + I(x^2), size = 1)
# alternative
reglin2$x2<-reglin2$xˆ2
head(reglin2)
# alternative
reglin2$x2<-reglin2$x^2
head(reglin2)
nlmod2<-lm(y~x+x2,data=reglin2)
summary(nlmod2)
# cubic
nlmod3<-lm(y~x+I(x^2)+I(x^3),data=reglin2)
summary(nlmod3)
reglin3 <- read.csv("ch2_part2_A_code/reglin3.csv")
head(reglin3)
# model without sex effect
mod.int <- lm(intent ~ fix, data=reglin3)
summary(mod.int)
# visualisation
ggplot(data = reglin3, aes(x = fix, y = intent)) +
geom_point(aes(col = as.factor(sex))) +
geom_smooth(method="lm", se=FALSE, formula="y ~ x", col="black", fullrange=TRUE)
# model without interaction
mod.int1<-lm(intent~as.factor(sex)+fix,data=reglin3)
summary(mod.int1)
# visualization
ggplot(reglin3, aes(x=fix, y=intent,col=as.factor(sex)))+
geom_point() +
geom_line(aes(y = pred.int1), size = 1)
# fitted values
pred.int1<-mod.int1$fitted.values
# visualization
ggplot(reglin3, aes(x=fix, y=intent,col=as.factor(sex)))+
geom_point() +
geom_line(aes(y = pred.int1), size = 1)
# model with interactions
mod.int2 <- lm(intent ~ as.factor(sex) * fix, data=reglin3)
summary(mod.int2)
# fitted value
pred.int2<-mod.int2$fitted.values
# visualization
ggplot(reglin3, aes(x=fix, y=intent,col=as.factor(sex)))+
geom_point() +
geom_line(aes(y = pred.int2), size = 1)
# alternative
ggplot(data = reglin3, aes(x = fix, y = intent, col = as.factor(sex))) +
geom_point() +
geom_smooth(method="lm", se=FALSE, formula="y ~ x", show.legend=FALSE, fullrange=TRUE)
# model with interactions + other variables
reglin6<-read.csv("ch2_part2_A_code//reglin6.csv")
head(reglin6)
mod.int3<-lm(intent~as.factor(sex)*fix+emo+age+as.factor(rev)+as.factor(educ)+stat,data=reglin6)
summary(mod.int3)
# illustration
ex<-read.table("ch2_part2_A_code//colinear.txt",header = TRUE)
head(ex)
attach(ex)
summary(age-age2)
cor(age, age3)
cor(age, age4)
library(Hmisc)
rcorr(cbind(age, age2, age3, age4))
summary(lm(height~age,data=ex))
summary(lm(height~age+age2,data=ex))
summary(lm(height~age,data=ex))
summary(lm(height~age3,data=ex))
summary(lm(height~age+age3,data=ex))
summary(lm(height~age,data=ex))
summary(lm(height~age4,data=ex))
summary(lm(height~age+age4,data=ex))
reglin8<-read.csv("ch2_part2_A_code//reglin8.csv")
head(reglin8)
rcorr(as.matrix(reglin8))
# VIF
library(car)
mod.col1<-lm(Y~.,data=reglin8)
summary(mod.col1)
vif(mod.col1)
attach(reglin8)
temp<-reglin8
temp$avg123<-(X1+X2+X3)/3
head(temp)
mod.col2<-lm(Y~avg123+X4+X5,data=temp)
summary(mod.col2)
vif(mod.col2)
comp <- read.csv("ch2_part3_A_code/comp.csv")
head(comp)
View(comp)
summary(comp)
table(comp$grp)
# t-test (two-side, bilateral)
t.test(off ~ grp, alternative="two.sided", var.equal=TRUE, conf.level=0.95 ,data=comp)
# Using Linear Regression
mod1 <- lm(off~grp, data=comp)
summary(mod1)
# Alternative: as.factor
summary(lm(off~as.factor(grp), data=comp))
confint(mod1)
# one-side (uilateral)
t.test(off~grp, alternative="less", var.equal=TRUE, conf.level=0.95, data=comp)
# Normality - residuals
# histogram
library(ggplot2)
ggplot(comp, aes(x = rstudent(mod1))) +
geom_density() +
geom_histogram(aes(y = after_stat(density)), bins = 20, alpha = 0.5)
# qqplot
ggplot(comp, mapping = aes(sample = rstudent(mod1))) +
stat_qq(distribution = qt, dparams = mod1$df.residual) +
stat_qq_line(distribution = qt, dparams = mod1$df.residual) +
labs(x = "theoretical quantiles", y = "empirical quantiles")
# Y
# histogram
ggplot(comp, aes(x = off)) +
geom_density() +
geom_histogram(aes(y = after_stat(density)), bins = 20, alpha = 0.5) +
facet_grid(grp ~ .)
# qqplot
ggplot(data = comp, aes(sample = off)) +
geom_qq( ) +
geom_qq_line( ) +
facet_grid(grp ~ .)
# test: egalite des variances / equality of variances
var.test(off~grp,data=comp,alternative="two.sided")
# Welch test
t.test(off~grp,alternative="two.sided",var.equal=FALSE,conf.level=0.95,data=comp)
# linear regression: generalized least squares
# allows for non-constant variance (and correlation)
library(nlme)
mod2 <- gls(off ~ grp, data = comp,
weights=varIdent(form = ~ 1 | grp))
mod2 <- gls(off ~ grp, data = comp, weights=varIdent(form = ~ 1 | grp))
summary(mod2)
library(emmeans)
m2 <- emmeans(mod2, specs = "grp")
m2
m2.cont <- contrast(m2, method="pairwise")
m2.cont
confint(m2.cont)
comp3 <- read.csv("ch2_part3_A_code/comp3.csv")
head(comp3)
summary(comp3)
table(comp3$ban)
stats<-data.frame(as.matrix(aggregate(score~ban, data=comp3, function(x)cbind(mean(x),sd(x),min(x),max(x),length(x)))))
names(stats)<-c("ban","mean","sd","min","max","n")
stats
library(dplyr)
group_by(comp3, ban) %>%
summarise(
mean = mean(score),
sd = sd(score),
min = min(score),
max = max(score),
count = n(),
)
# visualization
boxplot(score~as.factor(ban),data=comp3)
oneway.test(score ~ ban, data = comp3, var.equal = TRUE)
mod3<-lm(score~as.factor(ban),data=comp3)
summary(mod3)
library(car)
Anova(mod3)
# histograms
library(ggplot2)
ggplot(comp3, aes(x = score)) +
geom_density() +
geom_histogram(aes(y = after_stat(density)), bins = 20, alpha = 0.5) +
facet_grid(ban ~ .)
# qqplot
ggplot(data = comp3, aes(sample = score)) +
geom_qq( ) +
geom_qq_line( ) +
facet_grid(ban ~ .)
# test: equality of variance / egalites des variances
bartlett.test(score~as.factor(ban),data=comp3)
library(car)
leveneTest(score~as.factor(ban),data=comp3)
leveneTest(score~as.factor(ban),data=comp3,center=mean)
oneway.test(score ~ ban, data = comp3, var.equal = FALSE)
# Pairwise comparisons
# linear regression
library(nlme)
library(emmeans)
# constant variance
contrast(emmeans(mod3, ~ban),method="pairwise",adjust="none")
# different variance by bank
mod4 <- gls(score ~ as.factor(ban), data = comp3, weights=varIdent(form = ~ 1 | as.factor(ban)))
summary(mod4)
contrast(emmeans(mod4, ~ban),method="pairwise",adjust="none")
# Exemple: UX
comp4 <- read.csv("ch2_part3_A_code/comp4.csv")
head(comp4)
nrow(comp4)
summary(comp4)
View(comp4)
# main effects model
mod5<-lm(eval~as.factor(sta)+as.factor(del),data=comp4)
summary(mod5)
#
library(car)
Anova(mod5)
# interaction model
mod6<-lm(eval~as.factor(sta)*as.factor(del),data=comp4)
summary(mod6)
Anova(mod6)
anova(mod6,mod5)
Anova(mod6,error=mod5)
Anova(mod6,error=mod6)
Anova(mod6)
anova(mod6,lm(eval~as.factor(del),data=comp4))
anova(mod5,lm(eval~as.factor(del),data=comp4))
anova(mod5,lm(eval~as.factor(del),data=comp4),error=mod6)
anova(mod6,lm(eval~as.factor(sta),data=comp4))
anova(mod5,lm(eval~as.factor(sta),data=comp4))
anova(mod5,lm(eval~as.factor(sta),data=comp4),error=mod6)
# manually
data<-comp4
data$sta2<-as.numeric(comp4$sta==2)
data$del2<-as.numeric(comp4$del==2)
data$del3<-as.numeric(comp4$del==3)
data$int22<-as.numeric(comp4$sta==2 & comp4$del==2)
data$int23<-as.numeric(comp4$sta==2 & comp4$del==3)
head(data)
#
mod7<-lm(eval~sta2+del2+del3+int22+int23,data=data)
summary(mod7)
summary(mod6)
Anova(mod6,type=3)
anova(mod7,lm(eval~del2+del3+int22+int23,data=data))
anova(mod7,lm(eval~sta2+int22+int23,data=data))
emmeans(mod6, ~del*sta)
contrast(emmeans(mod6, ~del*sta),method="pairwise",adjust="none")
# testing equality of variance
data2<-comp4
data2$grp<-1*as.numeric(comp4$del==1 & comp4$sta==1) +
2*as.numeric(comp4$del==2 & comp4$sta==1)+
3*as.numeric(comp4$del==3 & comp4$sta==1)+
4*as.numeric(comp4$del==1 & comp4$sta==2)+
5*as.numeric(comp4$del==2 & comp4$sta==2)+
6*as.numeric(comp4$del==3 & comp4$sta==2)
head(data2)
# test: equality of variance
bartlett.test(eval~as.factor(grp),data=data2)
leveneTest(eval~as.factor(grp),data=data2)
leveneTest(eval~as.factor(grp),data=data2,center=mean)
library(nlme)
mod8 <- gls(eval ~ as.factor(del)*as.factor(sta), data = data2, weights=varIdent(form = ~ 1 | grp))
summary(mod8)
